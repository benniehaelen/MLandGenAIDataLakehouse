{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "468940dd-7e17-45dd-965a-bebe771e4404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"display:flex; align-items:flex-start; margin-bottom:1rem;\">\n",
    "  <!-- Left: Book cover -->\n",
    "  <img\n",
    "    src=\"https://adb-1376134742576436.16.azuredatabricks.net/files/Images/book_cover.JPG\"\n",
    "    style=\"width:35%; margin-right:1rem; border-radius:4px; box-shadow:0 2px 6px rgba(0,0,0,0.1);\"\n",
    "    alt=\"Book Cover\"/>\n",
    "  <!-- Right: Metadata -->\n",
    "  <div style=\"flex:1;\">\n",
    "    <!-- O'Reilly logo above title -->\n",
    "    <div style=\"display:flex; flex-direction:column; align-items:flex-start; margin-bottom:0.75rem;\">\n",
    "      <img\n",
    "        src=\"https://cdn.oreillystatic.com/images/sitewide-headers/oreilly_logo_mark_red.svg\"\n",
    "        style=\"height:2rem; margin-bottom:0.25rem;\"\n",
    "        alt=\"O‘Reilly\"/>\n",
    "      <span style=\"font-size:1.75rem; font-weight:bold; line-height:1.2;\">\n",
    "        AI, ML and GenAI in the Lakehouse\n",
    "      </span>\n",
    "    </div>\n",
    "    <!-- Details, now each on its own line -->\n",
    "    <div style=\"font-size:0.9rem; color:#555; margin-bottom:1rem; line-height:1.4;\">\n",
    "      <div><strong>Name:</strong> 09-00-Common-Code</div>\n",
    "      <div><strong>Author:</strong> Bennie Haelen</div>\n",
    "      <div><strong>Date:</strong> 7-26-2025</div>\n",
    "    </div>\n",
    "    <!-- Purpose -->\n",
    "    <div style=\"font-weight:600; margin-bottom:0.75rem;\">\n",
    "      Purpose: This notebook contains the common code for this chapter\n",
    "    </div>\n",
    "    <!-- Outline -->\n",
    "    <div style=\"margin-top:0;\">\n",
    "      <h3 style=\"margin:0 0 0.25rem;\">Table of Contents</h3>\n",
    "      <ol style=\"padding-left:1.25rem; margin:0; color:#333;\">\n",
    "        <li>Fetch Wikipedia articles and load them into a DataFrame</li>\n",
    "        <li>Extract/clean the text content-split it into manageable chunks</li>\n",
    "        <li>Calculate the embeddings</li>\n",
    "        <li>Store the embeddings in a Delta file</li>\n",
    "      </ol>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a6617dc-9b28-4ada-9795-bd5c6afc0dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9949ae00-15ec-4ec3-8fa4-c085f33893b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG_NAME = \"book_ai_ml_lakehouse\"\n",
    "SCHEMA_NAME  = \"rag\"\n",
    "VECTOR_SEARCH_ENDPOINT_NAME = \"book_ml_and_genai\"\n",
    "USER_NAME = \"bhaelen@gmail.com\"\n",
    "ENDPOINT_PREFIX = \"vs_endpoint_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b723cf3b-6128-4dc8-b8db-9adaf8fae6c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b5ebef8-3353-479f-9c45-6e293b1983c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd382eeb-8259-489f-92a5-b551d9008761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Endpoint functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c029d700-6c55-4024-acf8-0abd90133ac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Dict, Any, List\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class EndpointType(Enum):\n",
    "    \"\"\"Supported vector search endpoint types.\"\"\"\n",
    "    STANDARD = \"STANDARD\"\n",
    "    DATABRICKS_MANAGED_EMBEDDINGS = \"DATABRICKS_MANAGED_EMBEDDINGS\"\n",
    "\n",
    "\n",
    "def create_vector_search_endpoint(\n",
    "    client,\n",
    "    endpoint_name: str,\n",
    "    endpoint_type: EndpointType = EndpointType.STANDARD,\n",
    "    wait_for_ready: bool = True,\n",
    "    max_wait_time: int = 1800,  # 30 minutes\n",
    "    **kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a new vector search endpoint with the specified configuration.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name for the new endpoint\n",
    "        endpoint_type: Type of endpoint to create (default: STANDARD)\n",
    "        wait_for_ready: Whether to wait for endpoint to become ONLINE (default: True)\n",
    "        max_wait_time: Maximum time to wait for endpoint readiness in seconds (default: 1800)\n",
    "        **kwargs: Additional endpoint configuration parameters\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: The created endpoint configuration\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If endpoint creation fails or enters error state\n",
    "        TimeoutError: If endpoint doesn't become ready within max_wait_time\n",
    "        ValueError: If endpoint name is invalid or already exists\n",
    "        \n",
    "    Example:\n",
    "        >>> endpoint = create_vector_search_endpoint(\n",
    "        ...     client=vector_client,\n",
    "        ...     endpoint_name=\"my_endpoint\",\n",
    "        ...     endpoint_type=EndpointType.STANDARD\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    # Validate endpoint name\n",
    "    if not _is_valid_endpoint_name(endpoint_name):\n",
    "        raise ValueError(f\"Invalid endpoint name '{endpoint_name}'. Must contain only letters, numbers, and underscores.\")\n",
    "    \n",
    "    # Check if endpoint already exists\n",
    "    if _endpoint_exists(client, endpoint_name):\n",
    "        raise ValueError(f\"Endpoint '{endpoint_name}' already exists. Use a different name or delete the existing endpoint.\")\n",
    "    \n",
    "    try:\n",
    "        print(f\"Creating vector search endpoint: '{endpoint_name}' (type: {endpoint_type.value})\")\n",
    "        \n",
    "        # Prepare endpoint configuration\n",
    "        endpoint_config = {\n",
    "            \"name\": endpoint_name,\n",
    "            \"endpoint_type\": endpoint_type.value,\n",
    "            **kwargs\n",
    "        }\n",
    "        \n",
    "        # Create the endpoint\n",
    "        created_endpoint = client.create_endpoint(**endpoint_config)\n",
    "        print(f\"✓ Endpoint '{endpoint_name}' creation initiated successfully\")\n",
    "        \n",
    "        # Wait for endpoint to become ready if requested\n",
    "        if wait_for_ready:\n",
    "            print(f\"Waiting for endpoint '{endpoint_name}' to become ONLINE...\")\n",
    "            ready_endpoint = poll_vector_search_endpoint_status(\n",
    "                client=client,\n",
    "                endpoint_name=endpoint_name,\n",
    "                max_attempts=max_wait_time // 10,  # Poll every 10 seconds\n",
    "                poll_interval_seconds=10\n",
    "            )\n",
    "            print(f\"✓ Endpoint '{endpoint_name}' is now ready for use\")\n",
    "            return ready_endpoint\n",
    "        \n",
    "        return created_endpoint\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to create endpoint '{endpoint_name}': {str(e)}\"\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        raise RuntimeError(error_msg) from e\n",
    "\n",
    "\n",
    "def create_endpoint_with_fallback(\n",
    "    client,\n",
    "    username: str,\n",
    "    endpoint_prefix: str = \"vs_endpoint_\",\n",
    "    endpoint_type: EndpointType = EndpointType.STANDARD,\n",
    "    wait_for_ready: bool = True,\n",
    "    **kwargs\n",
    ") -> tuple[Dict[str, Any], str]:\n",
    "    \"\"\"\n",
    "    Create a vector search endpoint with automatic fallback naming.\n",
    "    \n",
    "    Attempts to create an endpoint with username-based naming, falling back\n",
    "    to a generic name if the primary name fails or already exists.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        username: Username to base the endpoint naming on\n",
    "        endpoint_prefix: Prefix for endpoint names (default: \"vs_endpoint_\")\n",
    "        endpoint_type: Type of endpoint to create (default: STANDARD)\n",
    "        wait_for_ready: Whether to wait for endpoint to become ONLINE\n",
    "        **kwargs: Additional endpoint configuration parameters\n",
    "    \n",
    "    Returns:\n",
    "        tuple[Dict[str, Any], str]: (created_endpoint, endpoint_name_used)\n",
    "        \n",
    "    Example:\n",
    "        >>> endpoint, name = create_endpoint_with_fallback(\n",
    "        ...     client=vector_client,\n",
    "        ...     username=\"john.doe@company.com\"\n",
    "        ... )\n",
    "        >>> print(f\"Created endpoint: {name}\")\n",
    "    \"\"\"\n",
    "    primary_name, fallback_name = configure_vector_search_endpoint(username, endpoint_prefix)\n",
    "    \n",
    "    # Try primary endpoint name first\n",
    "    try:\n",
    "        endpoint = create_vector_search_endpoint(\n",
    "            client=client,\n",
    "            endpoint_name=primary_name,\n",
    "            endpoint_type=endpoint_type,\n",
    "            wait_for_ready=wait_for_ready,\n",
    "            **kwargs\n",
    "        )\n",
    "        return endpoint, primary_name\n",
    "        \n",
    "    except (ValueError, RuntimeError) as e:\n",
    "        print(f\"Primary endpoint name '{primary_name}' failed: {e}\")\n",
    "        print(f\"Attempting fallback endpoint name '{fallback_name}'...\")\n",
    "        \n",
    "        # Try fallback name\n",
    "        try:\n",
    "            endpoint = create_vector_search_endpoint(\n",
    "                client=client,\n",
    "                endpoint_name=fallback_name,\n",
    "                endpoint_type=endpoint_type,\n",
    "                wait_for_ready=wait_for_ready,\n",
    "                **kwargs\n",
    "            )\n",
    "            return endpoint, fallback_name\n",
    "            \n",
    "        except (ValueError, RuntimeError) as fallback_error:\n",
    "            # If fallback also fails, try with a timestamp suffix\n",
    "            timestamp_name = f\"{fallback_name}_{int(time.time())}\"\n",
    "            print(f\"Fallback also failed: {fallback_error}\")\n",
    "            print(f\"Final attempt with timestamp: '{timestamp_name}'...\")\n",
    "            \n",
    "            endpoint = create_vector_search_endpoint(\n",
    "                client=client,\n",
    "                endpoint_name=timestamp_name,\n",
    "                endpoint_type=endpoint_type,\n",
    "                wait_for_ready=wait_for_ready,\n",
    "                **kwargs\n",
    "            )\n",
    "            return endpoint, timestamp_name\n",
    "\n",
    "\n",
    "def configure_vector_search_endpoint(username: str, endpoint_prefix: str = \"vs_endpoint_\") -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Configure vector search endpoint names based on user identity.\n",
    "    \n",
    "    Creates both a primary endpoint naming strategy and a fallback option\n",
    "    for vector search endpoint configuration.\n",
    "    \n",
    "    Args:\n",
    "        username: The username to base the endpoint naming on\n",
    "        endpoint_prefix: Prefix to use for endpoint names (default: \"vs_endpoint_\")\n",
    "    \n",
    "    Returns:\n",
    "        tuple[str, str]: A tuple containing (primary_endpoint_name, fallback_endpoint_name)\n",
    "        \n",
    "    Example:\n",
    "        >>> primary, fallback = configure_vector_search_endpoint(\"john.doe\")\n",
    "        >>> print(f\"Primary: {primary}, Fallback: {fallback}\")\n",
    "        Primary: vs_endpoint_john_doe, Fallback: vs_endpoint_fallback\n",
    "    \"\"\"\n",
    "    # Create fallback endpoint name for error scenarios\n",
    "    fallback_endpoint_name = f\"{endpoint_prefix}fallback\"\n",
    "    \n",
    "    # Generate primary endpoint name by sanitizing username\n",
    "    sanitized_username = _sanitize_username_for_endpoint(username)\n",
    "    primary_endpoint_name = f\"{endpoint_prefix}{sanitized_username}\"\n",
    "    \n",
    "    return primary_endpoint_name, fallback_endpoint_name\n",
    "\n",
    "\n",
    "def _sanitize_username_for_endpoint(username: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitize username for use in endpoint naming.\n",
    "    \n",
    "    Converts username to a format suitable for endpoint names by:\n",
    "    - Converting to lowercase\n",
    "    - Replacing dots and special characters with underscores\n",
    "    - Removing invalid characters\n",
    "    \n",
    "    Args:\n",
    "        username: Raw username string\n",
    "        \n",
    "    Returns:\n",
    "        str: Sanitized username suitable for endpoint naming\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Convert to lowercase and replace dots with underscores\n",
    "    sanitized = username.lower().replace(\".\", \"_\")\n",
    "    \n",
    "    # Remove any characters that aren't alphanumeric or underscores\n",
    "    sanitized = re.sub(r'[^a-z0-9_]', '', sanitized)\n",
    "    \n",
    "    # Ensure it doesn't start with a number\n",
    "    if sanitized and sanitized[0].isdigit():\n",
    "        sanitized = f\"user_{sanitized}\"\n",
    "    \n",
    "    return sanitized or \"anonymous\"\n",
    "\n",
    "\n",
    "def _is_valid_endpoint_name(name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validate endpoint name format.\n",
    "    \n",
    "    Args:\n",
    "        name: Endpoint name to validate\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if name is valid, False otherwise\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    if not name or len(name) < 1 or len(name) > 255:\n",
    "        return False\n",
    "    \n",
    "    # Check if name contains only valid characters\n",
    "    return bool(re.match(r'^[a-zA-Z0-9_]+$', name))\n",
    "\n",
    "\n",
    "def _endpoint_exists(client, endpoint_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if an endpoint with the given name already exists.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if endpoint exists, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.get_endpoint(endpoint_name)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def poll_vector_search_endpoint_status(\n",
    "    client,\n",
    "    endpoint_name: str,\n",
    "    max_attempts: int = 180,\n",
    "    poll_interval_seconds: int = 10,\n",
    "    log_frequency: int = 10\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Continuously polls a VectorSearchClient endpoint until it reaches ONLINE status.\n",
    "    \n",
    "    This function monitors the state of a vector search endpoint by repeatedly\n",
    "    checking its status until it becomes available or the maximum retry limit\n",
    "    is exceeded.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance used to query endpoint status\n",
    "        endpoint_name: Name of the vector search endpoint to monitor\n",
    "        max_attempts: Maximum number of polling attempts before timeout (default: 180)\n",
    "        poll_interval_seconds: Time to wait between status checks in seconds (default: 10)\n",
    "        log_frequency: How often to log status updates (every N attempts, default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: The endpoint configuration object when status becomes ONLINE\n",
    "    \n",
    "    Raises:\n",
    "        RuntimeError: When endpoint enters an unexpected error state\n",
    "        TimeoutError: When max_attempts is exceeded without reaching ONLINE status\n",
    "        \n",
    "    Example:\n",
    "        >>> endpoint = poll_vector_search_endpoint_status(\n",
    "        ...     client=vector_client,\n",
    "        ...     endpoint_name=\"my-search-endpoint\",\n",
    "        ...     max_attempts=120,\n",
    "        ...     poll_interval_seconds=15\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    last_known_state = \"\"\n",
    "    \n",
    "    for attempt_number in range(max_attempts):\n",
    "        try:\n",
    "            # Retrieve current endpoint configuration\n",
    "            endpoint_config = client.get_endpoint(endpoint_name)\n",
    "            \n",
    "            # Extract status from endpoint config (handles different SDK versions)\n",
    "            status_info = endpoint_config.get(\"endpoint_status\", endpoint_config.get(\"status\", {}))\n",
    "            current_state = status_info.get(\"state\", \"\").upper()\n",
    "            \n",
    "            # Store the last known state for error reporting\n",
    "            last_known_state = current_state\n",
    "            \n",
    "            # Check if endpoint is ready for use\n",
    "            if current_state == \"ONLINE\":\n",
    "                print(f\"✓ Endpoint '{endpoint_name}' is now ONLINE after {attempt_number + 1} attempts\")\n",
    "                return endpoint_config\n",
    "            \n",
    "            # Handle expected transitional states and early attempts\n",
    "            is_transitional_state = current_state in (\"PROVISIONING\", \"\")\n",
    "            is_early_attempt = attempt_number < 6\n",
    "            \n",
    "            if is_transitional_state or is_early_attempt:\n",
    "                # Log progress at specified intervals\n",
    "                if attempt_number % log_frequency == 0:\n",
    "                    status_display = current_state if current_state else \"UNKNOWN\"\n",
    "                    print(f\"[{attempt_number + 1:>3}/{max_attempts}] \"\n",
    "                          f\"Endpoint '{endpoint_name}' status: {status_display}, waiting...\")\n",
    "                \n",
    "                # Wait before next poll\n",
    "                time.sleep(poll_interval_seconds)\n",
    "            else:\n",
    "                # Endpoint is in an unexpected error state\n",
    "                raise RuntimeError(\n",
    "                    f\"Endpoint '{endpoint_name}' entered unexpected state '{current_state}'. \"\n",
    "                    f\"Full endpoint info: {endpoint_config}\"\n",
    "                )\n",
    "                \n",
    "        except (KeyError, AttributeError) as e:\n",
    "            # Handle cases where endpoint structure is unexpected\n",
    "            raise RuntimeError(\n",
    "                f\"Failed to parse endpoint status for '{endpoint_name}': {e}\"\n",
    "            ) from e\n",
    "    \n",
    "    # Timeout occurred - exceeded maximum attempts\n",
    "    raise TimeoutError(\n",
    "        f\"Timeout after {max_attempts} attempts ({max_attempts * poll_interval_seconds}s) \"\n",
    "        f\"waiting for endpoint '{endpoint_name}' to become ONLINE. \"\n",
    "        f\"Last known state: '{last_known_state}'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Additional utility functions\n",
    "def list_vector_search_endpoints(client) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    List all existing vector search endpoints.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: List of endpoint configurations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        endpoints = client.list_endpoints()\n",
    "        return endpoints.get(\"endpoints\", []) if hasattr(endpoints, 'get') else endpoints\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to list endpoints: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def delete_vector_search_endpoint(client, endpoint_name: str, force: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Delete a vector search endpoint.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name of the endpoint to delete\n",
    "        force: Whether to force deletion without confirmation\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if deletion was successful, False otherwise\n",
    "    \"\"\"\n",
    "    if not force:\n",
    "        response = input(f\"Are you sure you want to delete endpoint '{endpoint_name}'? (y/N): \")\n",
    "        if response.lower() not in ['y', 'yes']:\n",
    "            print(\"Deletion cancelled.\")\n",
    "            return False\n",
    "    \n",
    "    try:\n",
    "        client.delete_endpoint(endpoint_name)\n",
    "        print(f\"✓ Endpoint '{endpoint_name}' deleted successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to delete endpoint '{endpoint_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68a62057-4c13-4239-bf16-b3ed6c88d313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Index Management Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75115778-8291-44db-886c-9098e619c485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "\n",
    "class IndexPipelineType(Enum):\n",
    "    \"\"\"Supported vector index pipeline types.\"\"\"\n",
    "    TRIGGERED = \"TRIGGERED\"\n",
    "    CONTINUOUS = \"CONTINUOUS\"\n",
    "\n",
    "\n",
    "class IndexStatus(Enum):\n",
    "    \"\"\"Vector index status states.\"\"\"\n",
    "    PROVISIONING = \"PROVISIONING\"\n",
    "    ONLINE = \"ONLINE\"\n",
    "    OFFLINE = \"OFFLINE\"\n",
    "    FAILED = \"FAILED\"\n",
    "    SYNCING = \"SYNCING\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IndexConfiguration:\n",
    "    \"\"\"Configuration parameters for vector index creation.\"\"\"\n",
    "    source_table_name: str\n",
    "    index_name: str\n",
    "    endpoint_name: str\n",
    "    primary_key: str\n",
    "    embedding_vector_column: str\n",
    "    embedding_dimension: int\n",
    "    pipeline_type: IndexPipelineType = IndexPipelineType.TRIGGERED\n",
    "    sync_computed_embeddings: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate configuration parameters.\"\"\"\n",
    "        if self.embedding_dimension <= 0:\n",
    "            raise ValueError(\"Embedding dimension must be positive\")\n",
    "        if not all([self.source_table_name, self.index_name, self.endpoint_name, \n",
    "                   self.primary_key, self.embedding_vector_column]):\n",
    "            raise ValueError(\"All required configuration fields must be provided\")\n",
    "\n",
    "\n",
    "def create_or_sync_vector_index(\n",
    "    client,\n",
    "    catalog_name: str,\n",
    "    schema_name: str,\n",
    "    table_name: str,\n",
    "    index_name: str,\n",
    "    endpoint_name: str,\n",
    "    primary_key: str = \"id\",\n",
    "    embedding_dimension: int = 1024,\n",
    "    embedding_vector_column: str = \"embedding\",\n",
    "    pipeline_type: IndexPipelineType = IndexPipelineType.TRIGGERED,\n",
    "    sync_computed_embeddings: bool = False,\n",
    "    wait_for_ready: bool = True,\n",
    "    max_wait_time: int = 3600  # 1 hour\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a new vector index or sync an existing one with optimized configuration.\n",
    "    \n",
    "    This function handles the complete lifecycle of vector index management:\n",
    "    - Creates new indexes with proper configuration validation\n",
    "    - Syncs existing indexes to update with new data\n",
    "    - Monitors index status until ready for use\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        catalog_name: Unity Catalog name\n",
    "        schema_name: Schema name within the catalog\n",
    "        table_name: Source table name containing embeddings\n",
    "        index_name: Name for the vector search index\n",
    "        endpoint_name: Vector search endpoint to host the index\n",
    "        primary_key: Primary key column name (default: \"id\")\n",
    "        embedding_dimension: Dimension of embedding vectors (default: 1024)\n",
    "        embedding_vector_column: Column containing embedding vectors (default: \"embedding\")\n",
    "        pipeline_type: Index pipeline type (default: TRIGGERED)\n",
    "        sync_computed_embeddings: Whether to sync computed embeddings (default: False)\n",
    "        wait_for_ready: Whether to wait for index to become ready (default: True)\n",
    "        max_wait_time: Maximum time to wait for readiness in seconds (default: 3600)\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: The index configuration object\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If configuration parameters are invalid\n",
    "        RuntimeError: If index creation/sync fails\n",
    "        TimeoutError: If index doesn't become ready within max_wait_time\n",
    "        \n",
    "    Example:\n",
    "        >>> index = create_or_sync_vector_index(\n",
    "        ...     client=vector_client,\n",
    "        ...     catalog_name=\"my_catalog\",\n",
    "        ...     schema_name=\"my_schema\", \n",
    "        ...     table_name=\"embeddings_table\",\n",
    "        ...     index_name=\"my_vector_index\",\n",
    "        ...     endpoint_name=\"my_endpoint\",\n",
    "        ...     embedding_dimension=1536\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    print(f\"Catalog name: {catalog_name}\")\n",
    "    print(f\"Schema name: {schema_name}\")\n",
    "    print(f\"endpoint_name name: {endpoint_name}\")\n",
    "\n",
    "    # Construct full table and index names\n",
    "    source_table_fullname = f\"{catalog_name}.{schema_name}.{table_name}\"\n",
    "    index_fullname = f\"{catalog_name}.{schema_name}.{index_name}\"\n",
    "    \n",
    "    # Create configuration object for validation\n",
    "    config = IndexConfiguration(\n",
    "        source_table_name=source_table_fullname,\n",
    "        index_name=index_fullname,\n",
    "        endpoint_name=endpoint_name,\n",
    "        primary_key=primary_key,\n",
    "        embedding_vector_column=embedding_vector_column,\n",
    "        embedding_dimension=embedding_dimension,\n",
    "        pipeline_type=pipeline_type,\n",
    "        sync_computed_embeddings=sync_computed_embeddings\n",
    "    )\n",
    "    \n",
    "    print(f\"Managing vector index: {index_fullname}\")\n",
    "    print(f\"  Source table: {source_table_fullname}\")\n",
    "    print(f\"  Target endpoint: {endpoint_name}\")\n",
    "    print(f\"  Embedding dimension: {embedding_dimension}\")\n",
    "    \n",
    "    try:\n",
    "        # Check if index already exists\n",
    "        if not index_exists(client, endpoint_name, index_fullname):\n",
    "            print(f\"Creating new vector index '{index_fullname}' on endpoint '{endpoint_name}'...\")\n",
    "            \n",
    "            # Create the delta sync index\n",
    "            created_index = client.create_delta_sync_index(\n",
    "                endpoint_name=endpoint_name,\n",
    "                index_name=index_fullname,\n",
    "                source_table_name=source_table_fullname,\n",
    "                pipeline_type=pipeline_type.value,\n",
    "                primary_key=primary_key,\n",
    "                embedding_dimension=embedding_dimension,\n",
    "                embedding_vector_column=embedding_vector_column,\n",
    "                sync_computed_embeddings=sync_computed_embeddings\n",
    "            )\n",
    "            \n",
    "            print(f\"✓ Index creation initiated successfully\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Index '{index_fullname}' already exists, triggering sync...\")\n",
    "            \n",
    "            # Get existing index and trigger sync\n",
    "            existing_index = get_index(client, endpoint_name, index_fullname)\n",
    "            sync_result = existing_index.sync()\n",
    "            \n",
    "            print(f\"✓ Index sync triggered successfully\")\n",
    "            print(f\"  Sync operation ID: {sync_result.get('sync_id', 'N/A')}\")\n",
    "    \n",
    "        # Wait for index to be ready if requested\n",
    "        if wait_for_ready:\n",
    "            print(f\"Waiting for index '{index_fullname}' to be ready...\")\n",
    "            ready_index = wait_for_index_to_be_ready(\n",
    "                client=client,\n",
    "                endpoint_name=endpoint_name,\n",
    "                index_name=index_fullname,\n",
    "                max_wait_time=max_wait_time\n",
    "            )\n",
    "            print(f\"✓ Index '{index_fullname}' is now ready for queries\")\n",
    "            return ready_index\n",
    "        else:\n",
    "            # Return current index state without waiting\n",
    "            return get_index(client, endpoint_name, index_fullname)\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to create or sync index '{index_fullname}': {str(e)}\"\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        raise RuntimeError(error_msg) from e\n",
    "\n",
    "\n",
    "def index_exists(client, endpoint_name: str, index_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a vector search index exists on the specified endpoint.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name of the vector search endpoint\n",
    "        index_name: Full name of the index to check\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if index exists and is accessible, False otherwise\n",
    "        \n",
    "    Example:\n",
    "        >>> exists = index_exists(client, \"my_endpoint\", \"catalog.schema.my_index\")\n",
    "        >>> print(f\"Index exists: {exists}\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to get the index - if it exists, this will succeed\n",
    "        client.get_index(endpoint_name, index_name)\n",
    "        return True\n",
    "    except Exception:\n",
    "        # If any exception occurs (not found, access denied, etc.), index doesn't exist or isn't accessible\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_index(client, endpoint_name: str, index_name: str) -> Any:\n",
    "    \"\"\"\n",
    "    Retrieve a vector search index object with enhanced error handling.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name of the vector search endpoint\n",
    "        index_name: Full name of the index to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        Vector search index object\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If index cannot be retrieved or doesn't exist\n",
    "        \n",
    "    Example:\n",
    "        >>> index = get_index(client, \"my_endpoint\", \"catalog.schema.my_index\")\n",
    "        >>> status = index.describe()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        index_obj = client.get_index(endpoint_name, index_name)\n",
    "        return index_obj\n",
    "    except Exception as e:\n",
    "        error_msg = (\n",
    "            f\"Failed to retrieve index '{index_name}' from endpoint '{endpoint_name}'. \"\n",
    "            f\"Verify that both the endpoint and index exist and are accessible. Error: {str(e)}\"\n",
    "        )\n",
    "        raise RuntimeError(error_msg) from e\n",
    "\n",
    "\n",
    "def wait_for_index_to_be_ready(\n",
    "    client,\n",
    "    endpoint_name: str,\n",
    "    index_name: str,\n",
    "    max_wait_time: int = 3600,  # 1 hour default\n",
    "    poll_interval_seconds: int = 30,\n",
    "    log_frequency: int = 4  # Log every 4th attempt (every 2 minutes with 30s intervals)\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Poll a vector search index until it reaches a ready state for querying.\n",
    "    \n",
    "    This function continuously monitors the index status until it becomes ONLINE\n",
    "    and ready to serve queries, or until the maximum wait time is exceeded.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name of the vector search endpoint hosting the index\n",
    "        index_name: Full name of the index to monitor\n",
    "        max_wait_time: Maximum time to wait in seconds (default: 3600)\n",
    "        poll_interval_seconds: Time between status checks in seconds (default: 30)\n",
    "        log_frequency: How often to log status updates (every N attempts, default: 4)\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, Any]: The index status information when ready\n",
    "        \n",
    "    Raises:\n",
    "        RuntimeError: If index enters an error state or cannot be accessed\n",
    "        TimeoutError: If index doesn't become ready within max_wait_time\n",
    "        \n",
    "    Example:\n",
    "        >>> ready_index = wait_for_index_to_be_ready(\n",
    "        ...     client=vector_client,\n",
    "        ...     endpoint_name=\"my_endpoint\",\n",
    "        ...     index_name=\"catalog.schema.my_index\",\n",
    "        ...     max_wait_time=1800  # 30 minutes\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    max_attempts = max_wait_time // poll_interval_seconds\n",
    "    last_known_status = \"\"\n",
    "    \n",
    "    print(f\"Monitoring index readiness (max wait: {max_wait_time}s, poll interval: {poll_interval_seconds}s)\")\n",
    "    \n",
    "    for attempt_number in range(max_attempts):\n",
    "        try:\n",
    "            # Get current index status\n",
    "            index_obj = get_index(client, endpoint_name, index_name)\n",
    "            index_status = index_obj.describe()\n",
    "            \n",
    "            # Extract status information (handle different response formats)\n",
    "            if hasattr(index_status, 'get'):\n",
    "                current_status = index_status.get(\"status\", {}).get(\"ready\", False)\n",
    "                detailed_status = index_status.get(\"status\", {}).get(\"detailed_state\", \"UNKNOWN\")\n",
    "            else:\n",
    "                # Fallback for different SDK versions\n",
    "                current_status = getattr(index_status, 'ready', False)\n",
    "                detailed_status = getattr(index_status, 'detailed_state', \"UNKNOWN\")\n",
    "            \n",
    "            last_known_status = detailed_status\n",
    "            \n",
    "            # Check if index is ready for queries\n",
    "            if current_status:\n",
    "                print(f\"✓ Index '{index_name}' is now READY after {attempt_number + 1} attempts\")\n",
    "                print(f\"  Final status: {detailed_status}\")\n",
    "                return index_status\n",
    "            \n",
    "            # Handle different status states\n",
    "            if detailed_status.upper() in [\"PROVISIONING\", \"SYNCING\", \"ONLINE_NO_PENDING_UPDATE\"]:\n",
    "                # These are expected transitional states\n",
    "                if attempt_number % log_frequency == 0:\n",
    "                    elapsed_time = (attempt_number + 1) * poll_interval_seconds\n",
    "                    remaining_time = max_wait_time - elapsed_time\n",
    "                    print(f\"[{attempt_number + 1:>3}/{max_attempts}] \"\n",
    "                          f\"Index status: {detailed_status}, \"\n",
    "                          f\"elapsed: {elapsed_time}s, remaining: {remaining_time}s\")\n",
    "                \n",
    "                time.sleep(poll_interval_seconds)\n",
    "                \n",
    "            elif detailed_status.upper() in [\"FAILED\", \"OFFLINE\"]:\n",
    "                # These are error states\n",
    "                raise RuntimeError(\n",
    "                    f\"Index '{index_name}' entered error state: {detailed_status}. \"\n",
    "                    f\"Check the index configuration and source table. \"\n",
    "                    f\"Full status: {index_status}\"\n",
    "                )\n",
    "            else:\n",
    "                # Unknown state - log and continue for a few attempts\n",
    "                if attempt_number < 10:  # Give some time for unknown states\n",
    "                    if attempt_number % log_frequency == 0:\n",
    "                        print(f\"[{attempt_number + 1:>3}/{max_attempts}] \"\n",
    "                              f\"Unknown status: {detailed_status}, continuing...\")\n",
    "                    time.sleep(poll_interval_seconds)\n",
    "                else:\n",
    "                    raise RuntimeError(\n",
    "                        f\"Index '{index_name}' in unknown state: {detailed_status}. \"\n",
    "                        f\"Full status: {index_status}\"\n",
    "                    )\n",
    "                \n",
    "        except RuntimeError:\n",
    "            # Re-raise RuntimeError as-is (these are our custom errors)\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            # Handle unexpected errors during status checking\n",
    "            if attempt_number < 5:  # Retry a few times for transient errors\n",
    "                print(f\"Warning: Error checking index status (attempt {attempt_number + 1}): {e}\")\n",
    "                time.sleep(poll_interval_seconds)\n",
    "                continue\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    f\"Persistent error checking status for index '{index_name}': {e}\"\n",
    "                ) from e\n",
    "    \n",
    "    # Timeout occurred\n",
    "    elapsed_time = max_attempts * poll_interval_seconds\n",
    "    raise TimeoutError(\n",
    "        f\"Timeout after {elapsed_time}s waiting for index '{index_name}' to become ready. \"\n",
    "        f\"Last known status: {last_known_status}. \"\n",
    "        f\"Consider increasing max_wait_time or checking the index configuration.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def list_indexes_on_endpoint(client, endpoint_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    List all indexes on a specific vector search endpoint.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name of the vector search endpoint\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: List of index information dictionaries\n",
    "        \n",
    "    Example:\n",
    "        >>> indexes = list_indexes_on_endpoint(client, \"my_endpoint\")\n",
    "        >>> print(f\"Found {len(indexes)} indexes\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        endpoint_info = client.get_endpoint(endpoint_name)\n",
    "        return endpoint_info.get(\"endpoint_status\", {}).get(\"indexes\", [])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to list indexes for endpoint '{endpoint_name}': {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def delete_vector_index(client, endpoint_name: str, index_name: str, force: bool = False) -> bool:\n",
    "    \"\"\"\n",
    "    Delete a vector search index with confirmation.\n",
    "    \n",
    "    Args:\n",
    "        client: VectorSearchClient instance\n",
    "        endpoint_name: Name of the vector search endpoint\n",
    "        index_name: Full name of the index to delete\n",
    "        force: Whether to skip confirmation prompt (default: False)\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if deletion successful, False otherwise\n",
    "        \n",
    "    Example:\n",
    "        >>> deleted = delete_vector_index(client, \"my_endpoint\", \"catalog.schema.my_index\")\n",
    "    \"\"\"\n",
    "    if not force:\n",
    "        response = input(f\"Are you sure you want to delete index '{index_name}'? (y/N): \")\n",
    "        if response.lower() not in ['y', 'yes']:\n",
    "            print(\"Deletion cancelled.\")\n",
    "            return False\n",
    "    \n",
    "    try:\n",
    "        client.delete_index(endpoint_name, index_name)\n",
    "        print(f\"✓ Index '{index_name}' deleted successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to delete index '{index_name}': {e}\")\n",
    "        return False\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "9-00-Common-Code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
